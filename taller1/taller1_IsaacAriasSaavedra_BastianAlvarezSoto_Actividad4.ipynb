{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b151b0-95b8-4454-a00c-19643d919f12",
   "metadata": {},
   "source": [
    "# taller 1\n",
    "## Isaac Arias, Bastian Alvarez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4956363-1883-48ed-8c29-373781f4126b",
   "metadata": {},
   "source": [
    "#### funciones de verificacion para bibliotecas\n",
    "Estas funciones son cuando no se encuentran instaladas las bibliotecas\n",
    "y se instalan automaticamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2a2a7-591f-4ef7-bb8d-c2202dd39754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificacionPanda():\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import openpyxl as op\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ pandas no est√° instalado. Instalando Pandas, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\"])\n",
    "        subprocess.check_call([sys.executable,\"pip\", \"install\", \"openpyxl\"])\n",
    "        print(\"‚úÖ pandas instalado correctamente.\")\n",
    "\n",
    "\n",
    "\n",
    "def verificacionNumpy():\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ numpy no est√° instalado. Instalando Numpy, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\"])\n",
    "        import numpy as np\n",
    "        print(\"‚úÖ numpy instalado correctamente.\")\n",
    "\n",
    "def verificacionMatplotlib():\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ matplotlib no est√° instalado. Instalando matplotlib, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
    "        print(\"‚úÖ matplotlib instalado correctamente.\")\n",
    "\n",
    "def verificacionScikitLearn():\n",
    "    try:\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        from sklearn.cluster import KMeans\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ scikit-learn no est√° instalado. Instalando scikit-learn, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])\n",
    "        print(\"‚úÖ scikit-learn instalado correctamente.\")\n",
    "\n",
    "\n",
    "def verificacionSeaborn():\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ seaborn no est√° instalado. Instalando seaborn, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"])\n",
    "        print(\"‚úÖ seaborn instalado correctamente.\")\n",
    "\n",
    "def verificacionMlxtend():\n",
    "    try:\n",
    "        from mlxtend.preprocessing import TransactionEncoder\n",
    "        from mlxtend.frequent_patterns import apriori, association_rules\n",
    "        print(\"‚úÖ mlxtend ya est√° instalado y listo para usar.\")\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        print(\"üîÑ mlxtend no est√° instalado. Instalando mlxtend, espere un momento...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlxtend\"])\n",
    "        print(\"‚úÖ mlxtend instalado correctamente.\")\n",
    "\n",
    "\n",
    "\n",
    "def importacionDeBibliotecasAutomaticas():\n",
    "    verificacionPanda()\n",
    "    verificacionNumpy()\n",
    "    verificacionMatplotlib()\n",
    "    verificacionScikitLearn()\n",
    "    verificacionSeaborn()\n",
    "    verificacionMlxtend()\n",
    "importacionDeBibliotecasAutomaticas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9bd37",
   "metadata": {},
   "source": [
    "### Si tiene las depencencias instaladas ejecutar el codigo a continuacion\n",
    "\n",
    "\n",
    "Este odigo es solo para separar los archivos e importaciones,\n",
    "se toma por obiedad que los archivos csv y xlsx estaran en el mismo directorio que el archivo ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464c885-734c-43a5-a195-7ebce780a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "#se usa bravo como \"B\", charlie como \"C\" y delta como \"D\"\n",
    "#archivos de codigos\n",
    "archCodeDelta_Hoja1= pd.read_excel('Libro_C√≥digosADM2025_ArchivoD.xlsx', sheet_name=\"Postulaci√≥n y Selecci√≥n\")\n",
    "archCodeDelta_Hoja3= pd.read_excel('Libro_C√≥digosADM2025_ArchivoD.xlsx', sheet_name=\"Anexo -  Oferta acad√©mica\")\n",
    "archCodeCharlie_Hoja1= pd.read_excel('Libro_C√≥digosADM2025_ArchivoC.xlsx', sheet_name=\"Rinden\")\n",
    "\n",
    "#archivos de informacion importante\n",
    "archBravo = 'ArchivoB_Adm2025.csv'\n",
    "archDelta = 'ArchivoD_Adm2025.csv'\n",
    "archCharlie = 'ArchivoC_Adm2025.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datosBravo = pd.read_csv(archBravo,sep=\";\")\n",
    "datosDelta = pd.read_csv(archDelta,sep=\";\")\n",
    "datosCharlie = pd.read_csv(archCharlie,sep=\";\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a298c",
   "metadata": {},
   "source": [
    "### Actividad 1: Descripci√≥n del set de datos\n",
    "\n",
    "En esta primera parte del taller se integraron los archivos B, C y D en un solo conjunto de datos utilizando `ID_aux` como clave principal.  \n",
    "Luego, se filtr√≥ para mantener solo una postulaci√≥n por estudiante (preferencia n√∫mero 1).  \n",
    "\n",
    "Se realiz√≥ el an√°lisis exploratorio de variables:\n",
    "- **Num√©rica:** `PTJE_NEM`, donde se observ√≥ su rango y dispersi√≥n.\n",
    "- **Nominal:** `NOMBRE_UNIVERSIDAD`, representada gr√°ficamente por distribuci√≥n de postulaciones.\n",
    "- **Ordinal:** `SITUACION_EGRESO_y`, que fue mapeada con etiquetas explicativas para su an√°lisis con `countplot`.\n",
    "\n",
    "Este an√°lisis permiti√≥ conocer la composici√≥n general del dataset y caracter√≠sticas relevantes para los an√°lisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9292c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datosBC = pd.merge(datosBravo,datosCharlie,on=\"ID_aux\",how=\"left\")\n",
    "datosUnidos = pd.merge(datosBC,datosDelta,on=\"ID_aux\",how=\"left\")\n",
    "datosUnidos.head()\n",
    "\n",
    "# Primero nos aseguramos que ORDEN_PREF sea num√©rico\n",
    "datosUnidos['ORDEN_PREF'] = pd.to_numeric(datosUnidos['ORDEN_PREF'], errors='coerce')\n",
    "\n",
    "# Ahora seleccionamos la postulaci√≥n de menor ORDEN_PREF (es decir, preferencia 1 si existe)\n",
    "datosUnidos_filtrado = datosUnidos.sort_values(by=['ID_aux', 'ORDEN_PREF'])\n",
    "temp = datosUnidos_filtrado #almaceno esto para la actividad 4\n",
    "datosUnidos_filtrado.drop_duplicates(subset='ID_aux', keep='first') \n",
    "\n",
    "# Mostrar resultado\n",
    "datosUnidos_filtrado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed088d3",
   "metadata": {},
   "source": [
    "#### Variables numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f587a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "varNumerica = datosUnidos_filtrado[\"MATE1_REG_ACTUAL\"]\n",
    "print(\"min: \" , varNumerica.min())\n",
    "print(\"max: \", varNumerica.max())\n",
    "print(\"media: \", round(varNumerica.mean(),3))\n",
    "print(\"desv estand: \", round(varNumerica.std(),3) )\n",
    "\n",
    "\n",
    "# Histograma\n",
    "plt.hist(varNumerica, bins=30, edgecolor='black')\n",
    "plt.title('Distribuci√≥n del puntaje en Matem√°ticas')\n",
    "plt.xlabel('Puntaje')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37488b",
   "metadata": {},
   "source": [
    "#### Variables Nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "NEMxCarrera = pd.merge(datosUnidos_filtrado,archCodeDelta_Hoja3 , left_on=\"COD_CARRERA_PREF\", right_on=\"CODIGO_CARRERA\", how=\"left\")\n",
    "columnasNecesarias = [\"ID_aux\",\"NOMBRE_UNIVERSIDAD\", \"PTJE_NEM\", \"NOMBRE_CARRERA\"]\n",
    "todasLasUniversidades = NEMxCarrera[\"NOMBRE_UNIVERSIDAD\"].unique().tolist()\n",
    "distribucion_postulaciones = NEMxCarrera['NOMBRE_UNIVERSIDAD'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Tama√±o del gr√°fico\n",
    "distribucion_postulaciones.plot(kind='bar', color='skyblue')  # Gr√°fico de barras\n",
    "plt.title('Distribuci√≥n de Postulaciones por Universidad', fontsize=16)\n",
    "plt.xlabel('Universidad', fontsize=14)\n",
    "plt.ylabel('N√∫mero de Postulaciones', fontsize=14)\n",
    "plt.xticks(rotation=90)  # Gira las etiquetas de las universidades para que no se superpongan\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2aacb",
   "metadata": {},
   "source": [
    "#### Variable Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c3488-8df9-4da1-96b1-e147714ae84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributo_ordinal = 'SITUACION_EGRESO_y' \n",
    "print(f\"\\nAn√°lisis del atributo: {atributo_ordinal}\")\n",
    "print(datosUnidos_filtrado[atributo_ordinal].value_counts())\n",
    "mapeo_situacion = {\n",
    "    1: \"1. Promoci√≥n del A√±o: Nacional ‚Äì alumno regular\",\n",
    "    2: \"2. Promoci√≥n del A√±o: Nacional ‚Äì validaci√≥n de estudios\",\n",
    "    3: \"3. Promoci√≥n del A√±o: Extranjero ‚Äì con alg√∫n curso en Chile\",\n",
    "    4: \"4. Promoci√≥n del A√±o: Extranjero ‚Äì no acredita notas\",\n",
    "    5: \"5. Promoci√≥n Anterior: Nacional ‚Äì  alumno regular\",\n",
    "    6: \"6. Promoci√≥n Anterior: Nacional ‚Äì validaci√≥n de estudios\",\n",
    "    7: \"7. Promoci√≥n Anterior Extranjero ‚Äì con alg√∫n curso en Chile\",\n",
    "    8: \"8. Promoci√≥n Anterior Extranjero ‚Äì no acredita notas\",\n",
    "}\n",
    "\n",
    "datosUnidos_filtrado['SITUACION_EGRESO_y'] = pd.to_numeric(datosUnidos_filtrado['SITUACION_EGRESO_y']).astype('Int64')\n",
    "\n",
    "# 3. Gr√°fico pero usando el mapeo en el eje\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.countplot(x='SITUACION_EGRESO_y',  data=datosUnidos_filtrado, order=sorted(mapeo_situacion.keys()))\n",
    "plt.xticks(ticks=range(len(mapeo_situacion)), labels=[mapeo_situacion[k] for k in sorted(mapeo_situacion.keys())], rotation=90)\n",
    "plt.xlabel(\"Situaci√≥n de Egreso\")\n",
    "plt.ylabel(\"Cantidad de postulantes\")\n",
    "plt.title(\"Distribuci√≥n de la Situaci√≥n de Egreso actual\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0399b9",
   "metadata": {},
   "source": [
    "# Actividad 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3de1dd-b398-4d39-a21f-e27ef50cc026",
   "metadata": {},
   "source": [
    "## Analisis de Datos\n",
    "\n",
    "* Primer Dato: \"PTJE_NEM\".\n",
    "  \n",
    "     Es el Puntaje de Notas de Ense√±anza Media. Se usa directamente en los an√°lisis de rendimiento acad√©mico, clustering, y segmentaciones.                 Un valor nulo o fuera de rango podr√≠a afectar seriamente la calidad del agrupamiento.\n",
    "\n",
    "\n",
    "\n",
    "* Segundo Dato: \"PTJE_RANKING\".\n",
    "\n",
    "    Es el Puntaje de Ranking Escolar. Complementa al NEM, mide el desempe√±o relativo dentro del colegio. Tambi√©n es muy importante para                    clasificaci√≥n y agrupamientos. Un valor nulo o at√≠pico afectar√≠a interpretaciones\n",
    "\n",
    "\n",
    "\n",
    "* Tercer Dato: \"ORDEN_PREF\".\n",
    "\n",
    "    Indica el orden de preferencia de las postulaciones del postulante. Es fundamental para definir cu√°l carrera fue m√°s importante para el alumno. Si     este dato es err√≥neo o est√° mal tipeado, distorsionar√≠a todo el an√°lisis de postulaciones prioritarias.\n",
    "\n",
    "\n",
    "* Cuarto Dato: \"COD_CARRERA_PREF\".\n",
    "\n",
    "    Es el c√≥digo de carrera a la que postula cada alumno. Es vital para las reglas de asociaci√≥n (una de las actividades obligatorias del taller). Si      faltan c√≥digos, no podr√≠as relacionar carreras correctamente en la fase de extracci√≥n de reglas.\n",
    "\n",
    "\n",
    "\n",
    "___________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "  >Estas tareas no solo mejoraron la calidad t√©cnica del dataset, sino que garantizaron que los modelos posteriores (clustering y reglas) funcionen sobre datos representativos y consistentes.\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba118476",
   "metadata": {},
   "source": [
    "**Eliminaci√≥n de valores nulos cr√≠ticos:** registros sin `PTJE_NEM` fueron eliminados, ya que la ausencia de este puntaje impide an√°lisis v√°lidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62870a8f-b5e3-4413-bcba-057d1ac1c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar nulos\n",
    "print(\"Valores nulos en PTJE_NEM:\", datosUnidos_filtrado['PTJE_NEM'].isnull().sum())\n",
    "\n",
    "# Eliminar registros sin PTJE_NEM\n",
    "datosUnidos_filtrado = datosUnidos_filtrado.dropna(subset=['PTJE_NEM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cff9d470-b7f6-4e43-ac44-0ec197f142bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_aux</th>\n",
       "      <th>ANYO_PROCESO</th>\n",
       "      <th>FECHA_NACIMIENTO</th>\n",
       "      <th>RBD_x</th>\n",
       "      <th>COD_ENS_x</th>\n",
       "      <th>REGIMEN</th>\n",
       "      <th>RAMA_EDUCACIONAL_x</th>\n",
       "      <th>GRUPO_DEPENDENCIA_x</th>\n",
       "      <th>ANYO_EGRESO</th>\n",
       "      <th>CODIGO_REGION_x</th>\n",
       "      <th>CODIGO_PROVINCIA</th>\n",
       "      <th>CODIGO_COMUNA_x</th>\n",
       "      <th>CODIGO_REGION_D</th>\n",
       "      <th>CODIGO_COMUNA_D</th>\n",
       "      <th>SITUACION_EGRESO_x</th>\n",
       "      <th>BEA</th>\n",
       "      <th>PACE</th>\n",
       "      <th>PAIS_NACIMIENTO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>INGRESO_PERCAPITA_GRUPO_FA</th>\n",
       "      <th>RINDIO_PROCESO_ANTERIOR</th>\n",
       "      <th>RINDIO_PROCESO_ACTUAL</th>\n",
       "      <th>RBD_y</th>\n",
       "      <th>COD_ENS_y</th>\n",
       "      <th>GRUPO_DEPENDENCIA_y</th>\n",
       "      <th>RAMA_EDUCACIONAL_y</th>\n",
       "      <th>SITUACION_EGRESO_y</th>\n",
       "      <th>CODIGO_REGION_y</th>\n",
       "      <th>CODIGO_COMUNA_y</th>\n",
       "      <th>PROMEDIO_NOTAS</th>\n",
       "      <th>PORC_SUP_NOTAS</th>\n",
       "      <th>PTJE_NEM</th>\n",
       "      <th>PTJE_RANKING</th>\n",
       "      <th>CLEC_REG_ACTUAL</th>\n",
       "      <th>MATE1_REG_ACTUAL</th>\n",
       "      <th>MATE2_REG_ACTUAL</th>\n",
       "      <th>HCSOC_REG_ACTUAL</th>\n",
       "      <th>CIEN_REG_ACTUAL</th>\n",
       "      <th>MODULO_REG_ACTUAL</th>\n",
       "      <th>CLEC_INV_ACTUAL</th>\n",
       "      <th>MATE1_INV_ACTUAL</th>\n",
       "      <th>MATE2_INV_ACTUAL</th>\n",
       "      <th>HCSOC_INV_ACTUAL</th>\n",
       "      <th>CIEN_INV_ACTUAL</th>\n",
       "      <th>MODULO_INV_ACTUAL</th>\n",
       "      <th>CLEC_REG_ANTERIOR</th>\n",
       "      <th>MATE1_REG_ANTERIOR</th>\n",
       "      <th>MATE2_REG_ANTERIOR</th>\n",
       "      <th>HCSOC_REG_ANTERIOR</th>\n",
       "      <th>CIEN_REG_ANTERIOR</th>\n",
       "      <th>MODULO_REG_ANTERIOR</th>\n",
       "      <th>CLEC_INV_ANTERIOR</th>\n",
       "      <th>MATE1_INV_ANTERIOR</th>\n",
       "      <th>MATE2_INV_ANTERIOR</th>\n",
       "      <th>HCSOC_INV_ANTERIOR</th>\n",
       "      <th>CIEN_INV_ANTERIOR</th>\n",
       "      <th>MODULO_INV_ANTERIOR</th>\n",
       "      <th>ORDEN_PREF</th>\n",
       "      <th>COD_CARRERA_PREF</th>\n",
       "      <th>ESTADO_PREF</th>\n",
       "      <th>TIPO_PREF</th>\n",
       "      <th>PTJE_PREF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID_aux, ANYO_PROCESO, FECHA_NACIMIENTO, RBD_x, COD_ENS_x, REGIMEN, RAMA_EDUCACIONAL_x, GRUPO_DEPENDENCIA_x, ANYO_EGRESO, CODIGO_REGION_x, CODIGO_PROVINCIA, CODIGO_COMUNA_x, CODIGO_REGION_D, CODIGO_COMUNA_D, SITUACION_EGRESO_x, BEA, PACE, PAIS_NACIMIENTO, SEXO, INGRESO_PERCAPITA_GRUPO_FA, RINDIO_PROCESO_ANTERIOR, RINDIO_PROCESO_ACTUAL, RBD_y, COD_ENS_y, GRUPO_DEPENDENCIA_y, RAMA_EDUCACIONAL_y, SITUACION_EGRESO_y, CODIGO_REGION_y, CODIGO_COMUNA_y, PROMEDIO_NOTAS, PORC_SUP_NOTAS, PTJE_NEM, PTJE_RANKING, CLEC_REG_ACTUAL, MATE1_REG_ACTUAL, MATE2_REG_ACTUAL, HCSOC_REG_ACTUAL, CIEN_REG_ACTUAL, MODULO_REG_ACTUAL, CLEC_INV_ACTUAL, MATE1_INV_ACTUAL, MATE2_INV_ACTUAL, HCSOC_INV_ACTUAL, CIEN_INV_ACTUAL, MODULO_INV_ACTUAL, CLEC_REG_ANTERIOR, MATE1_REG_ANTERIOR, MATE2_REG_ANTERIOR, HCSOC_REG_ANTERIOR, CIEN_REG_ANTERIOR, MODULO_REG_ANTERIOR, CLEC_INV_ANTERIOR, MATE1_INV_ANTERIOR, MATE2_INV_ANTERIOR, HCSOC_INV_ANTERIOR, CIEN_INV_ANTERIOR, MODULO_INV_ANTERIOR, ORDEN_PREF, COD_CARRERA_PREF, ESTADO_PREF, TIPO_PREF, PTJE_PREF]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corregir tipo de dato\n",
    "datosUnidos_filtrado['ORDEN_PREF'] = pd.to_numeric(datosUnidos_filtrado['ORDEN_PREF'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(datosUnidos_filtrado['ORDEN_PREF'].dtypes)\n",
    "datosUnidos_filtrado[(datosUnidos_filtrado['PTJE_NEM'] == 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aed754fc-0212-4a96-9338-4a2387d8adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.613249e+06\n",
      "mean     7.820997e+02\n",
      "std      1.118155e+02\n",
      "min      3.870000e+02\n",
      "25%      6.940000e+02\n",
      "50%      7.850000e+02\n",
      "75%      8.710000e+02\n",
      "max      1.000000e+03\n",
      "Name: PTJE_NEM, dtype: float64\n",
      "count    1.597117e+06\n",
      "mean     8.042097e+02\n",
      "std      1.215612e+02\n",
      "min      5.760000e+02\n",
      "25%      7.040000e+02\n",
      "50%      8.080000e+02\n",
      "75%      9.080000e+02\n",
      "max      1.000000e+03\n",
      "Name: PTJE_RANKING, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_aux</th>\n",
       "      <th>ANYO_PROCESO</th>\n",
       "      <th>FECHA_NACIMIENTO</th>\n",
       "      <th>RBD_x</th>\n",
       "      <th>COD_ENS_x</th>\n",
       "      <th>REGIMEN</th>\n",
       "      <th>RAMA_EDUCACIONAL_x</th>\n",
       "      <th>GRUPO_DEPENDENCIA_x</th>\n",
       "      <th>ANYO_EGRESO</th>\n",
       "      <th>CODIGO_REGION_x</th>\n",
       "      <th>CODIGO_PROVINCIA</th>\n",
       "      <th>CODIGO_COMUNA_x</th>\n",
       "      <th>CODIGO_REGION_D</th>\n",
       "      <th>CODIGO_COMUNA_D</th>\n",
       "      <th>SITUACION_EGRESO_x</th>\n",
       "      <th>BEA</th>\n",
       "      <th>PACE</th>\n",
       "      <th>PAIS_NACIMIENTO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>INGRESO_PERCAPITA_GRUPO_FA</th>\n",
       "      <th>RINDIO_PROCESO_ANTERIOR</th>\n",
       "      <th>RINDIO_PROCESO_ACTUAL</th>\n",
       "      <th>RBD_y</th>\n",
       "      <th>COD_ENS_y</th>\n",
       "      <th>GRUPO_DEPENDENCIA_y</th>\n",
       "      <th>RAMA_EDUCACIONAL_y</th>\n",
       "      <th>SITUACION_EGRESO_y</th>\n",
       "      <th>CODIGO_REGION_y</th>\n",
       "      <th>CODIGO_COMUNA_y</th>\n",
       "      <th>PROMEDIO_NOTAS</th>\n",
       "      <th>PORC_SUP_NOTAS</th>\n",
       "      <th>PTJE_NEM</th>\n",
       "      <th>PTJE_RANKING</th>\n",
       "      <th>CLEC_REG_ACTUAL</th>\n",
       "      <th>MATE1_REG_ACTUAL</th>\n",
       "      <th>MATE2_REG_ACTUAL</th>\n",
       "      <th>HCSOC_REG_ACTUAL</th>\n",
       "      <th>CIEN_REG_ACTUAL</th>\n",
       "      <th>MODULO_REG_ACTUAL</th>\n",
       "      <th>CLEC_INV_ACTUAL</th>\n",
       "      <th>MATE1_INV_ACTUAL</th>\n",
       "      <th>MATE2_INV_ACTUAL</th>\n",
       "      <th>HCSOC_INV_ACTUAL</th>\n",
       "      <th>CIEN_INV_ACTUAL</th>\n",
       "      <th>MODULO_INV_ACTUAL</th>\n",
       "      <th>CLEC_REG_ANTERIOR</th>\n",
       "      <th>MATE1_REG_ANTERIOR</th>\n",
       "      <th>MATE2_REG_ANTERIOR</th>\n",
       "      <th>HCSOC_REG_ANTERIOR</th>\n",
       "      <th>CIEN_REG_ANTERIOR</th>\n",
       "      <th>MODULO_REG_ANTERIOR</th>\n",
       "      <th>CLEC_INV_ANTERIOR</th>\n",
       "      <th>MATE1_INV_ANTERIOR</th>\n",
       "      <th>MATE2_INV_ANTERIOR</th>\n",
       "      <th>HCSOC_INV_ANTERIOR</th>\n",
       "      <th>CIEN_INV_ANTERIOR</th>\n",
       "      <th>MODULO_INV_ANTERIOR</th>\n",
       "      <th>ORDEN_PREF</th>\n",
       "      <th>COD_CARRERA_PREF</th>\n",
       "      <th>ESTADO_PREF</th>\n",
       "      <th>TIPO_PREF</th>\n",
       "      <th>PTJE_PREF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID_aux, ANYO_PROCESO, FECHA_NACIMIENTO, RBD_x, COD_ENS_x, REGIMEN, RAMA_EDUCACIONAL_x, GRUPO_DEPENDENCIA_x, ANYO_EGRESO, CODIGO_REGION_x, CODIGO_PROVINCIA, CODIGO_COMUNA_x, CODIGO_REGION_D, CODIGO_COMUNA_D, SITUACION_EGRESO_x, BEA, PACE, PAIS_NACIMIENTO, SEXO, INGRESO_PERCAPITA_GRUPO_FA, RINDIO_PROCESO_ANTERIOR, RINDIO_PROCESO_ACTUAL, RBD_y, COD_ENS_y, GRUPO_DEPENDENCIA_y, RAMA_EDUCACIONAL_y, SITUACION_EGRESO_y, CODIGO_REGION_y, CODIGO_COMUNA_y, PROMEDIO_NOTAS, PORC_SUP_NOTAS, PTJE_NEM, PTJE_RANKING, CLEC_REG_ACTUAL, MATE1_REG_ACTUAL, MATE2_REG_ACTUAL, HCSOC_REG_ACTUAL, CIEN_REG_ACTUAL, MODULO_REG_ACTUAL, CLEC_INV_ACTUAL, MATE1_INV_ACTUAL, MATE2_INV_ACTUAL, HCSOC_INV_ACTUAL, CIEN_INV_ACTUAL, MODULO_INV_ACTUAL, CLEC_REG_ANTERIOR, MATE1_REG_ANTERIOR, MATE2_REG_ANTERIOR, HCSOC_REG_ANTERIOR, CIEN_REG_ANTERIOR, MODULO_REG_ANTERIOR, CLEC_INV_ANTERIOR, MATE1_INV_ANTERIOR, MATE2_INV_ANTERIOR, HCSOC_INV_ANTERIOR, CIEN_INV_ANTERIOR, MODULO_INV_ANTERIOR, ORDEN_PREF, COD_CARRERA_PREF, ESTADO_PREF, TIPO_PREF, PTJE_PREF]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(datosUnidos_filtrado['PTJE_NEM'].describe())\n",
    "# Detectar l√≠mites\n",
    "q1 = datosUnidos_filtrado['PTJE_RANKING'].quantile(0.01)\n",
    "q99 = datosUnidos_filtrado['PTJE_RANKING'].quantile(0.99)\n",
    "\n",
    "# Filtrar datos dentro del rango\n",
    "datosUnidos_filtrado = datosUnidos_filtrado[(datosUnidos_filtrado['PTJE_RANKING'] >= q1) & (datosUnidos_filtrado['PTJE_RANKING'] <= q99)]\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(datosUnidos_filtrado['PTJE_RANKING'].describe())\n",
    "\n",
    "datosUnidos_filtrado[(datosUnidos_filtrado['PTJE_NEM'] == 0)].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c04939",
   "metadata": {},
   "source": [
    "**Imputaci√≥n categ√≥rica:** valores faltantes en `COD_CARRERA_PREF` se reemplazaron por `\"Sin carrera\"`, lo cual evita perder registros en el an√°lisis de reglas de asociaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea5962-8b97-4515-aa15-b1b37b246c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver cu√°ntos valores faltan en COD_CARRERA_PREF\n",
    "print(\"Valores nulos antes:\", datosUnidos_filtrado['COD_CARRERA_PREF'].isnull().sum())\n",
    "\n",
    "# Imputar con una categor√≠a gen√©rica\n",
    "datosUnidos_filtrado['COD_CARRERA_PREF'].fillna('Sin carrera', inplace=True)\n",
    "\n",
    "# Verificar que ya no haya nulos\n",
    "print(\"Valores nulos despu√©s:\", datosUnidos_filtrado['COD_CARRERA_PREF'].isnull().sum())\n",
    "datosUnidos_filtrado[(datosUnidos_filtrado['PTJE_NEM'] == 0)].info()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a247fd5",
   "metadata": {},
   "source": [
    "##### **Verificacion:** \n",
    "Se verifican los valores de NEM = 0 para ver si es posible eliminarlos o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8ca01-f5cd-4ad8-9a5f-1eb66b114073",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.arange(len(datosUnidos_filtrado))\n",
    "\n",
    "\n",
    "\n",
    "datosUnidos_filtrado2 = datosUnidos_filtrado\n",
    "datosUnidos_filtrado2 = datosUnidos_filtrado2[(datosUnidos_filtrado2['PTJE_NEM'] == 0)] #solo los valores 0\n",
    "\n",
    "columnasNecesarias = [\"ID_aux\",\"FECHA_NACIMIENTO\" ,\"MATE1_REG_ACTUAL\", \"MATE2_REG_ACTUAL\", \"HCSOC_REG_ACTUAL\", \"CIEN_REG_ACTUAL\", \"MODULO_REG_ACTUAL\",\n",
    "                      \"CLEC_INV_ACTUAL\", \"MATE1_INV_ACTUAL\", \"MATE2_INV_ACTUAL\", \"HCSOC_INV_ACTUAL\",\"CIEN_INV_ACTUAL\",\"MODULO_INV_ACTUAL\", \"CLEC_REG_ANTERIOR\", \"MATE1_REG_ANTERIOR\",\n",
    "                      \"MATE2_REG_ANTERIOR\", \"HCSOC_REG_ANTERIOR\", \"CIEN_REG_ANTERIOR\", \"CLEC_INV_ANTERIOR\",  \"MATE1_INV_ANTERIOR\", \"MATE2_INV_ANTERIOR\",\"HCSOC_INV_ANTERIOR\",\"CIEN_INV_ANTERIOR\",\n",
    "                    ]\n",
    "\n",
    "# Creamos una lista sin 'FECHA_NACIMIENTO'\n",
    "columnas_sin_fecha = [col for col in columnasNecesarias if col != \"FECHA_NACIMIENTO\"]\n",
    "\n",
    "# Aplicamos el filtro\n",
    "filtro = (datosUnidos_filtrado2[columnas_sin_fecha] == 0).all(axis=1) #filtro para que me almacene solo los postulantes que sus pruebas sean 0\n",
    "\n",
    "# Filtramos las filas\n",
    "datos_filtrados3 = datosUnidos_filtrado2[filtro]\n",
    "print(\"numero de postulantes con nem = 0 que no han rendido ninguna prueba: \", len(datos_filtrados3) , \n",
    "      \"\\nnumero de postulantes con nem = 0  que almenos hayan rendido 1 prueba: \", len(datosUnidos_filtrado2) - len(datos_filtrados3)) #si se eliminan se perderia informacion de las pruebas\n",
    "\n",
    "\n",
    "repeticiones_df = datosUnidos_filtrado2[\"ID_aux\"].value_counts().reset_index()\n",
    "repeticiones_df.columns = [\"ID_aux\", \"Repeticiones\"]\n",
    "\n",
    "# Filtrar los que se repiten 2 veces o m√°s\n",
    "repetidos = repeticiones_df[repeticiones_df[\"Repeticiones\"] >= 2]\n",
    "print(repetidos) # si esta vacio es que no hay repiticiones de id en el dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b5e55",
   "metadata": {},
   "source": [
    "Al demostrar que existen postulantes con nem = 0 pero estos poseen un puntaje mayores a 0 en sus pruebas, al eliminarlos podria afectar a la informacion y medidas de dispercion de las pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46851d",
   "metadata": {},
   "source": [
    "# Actividad 3\n",
    "El objetivo de esta actividad fue **agrupar a los postulantes seg√∫n su rendimiento acad√©mico** usando algoritmos de clustering.  \n",
    "Se eligieron las variables `PTJE_NEM` y `PTJE_RANKING` por ser indicadores cuantificables y comparables del desempe√±o escolar del estudiante, comunes en el proceso de admisi√≥n.\n",
    "\n",
    "Se usaron dos algoritmos (KMeans y DBSCAN), cada uno con dos configuraciones. En la primera configuraci√≥n se usaron los datos escalados directamente. En la segunda, se aplic√≥ PCA para reducir dimensionalidad y facilitar la visualizaci√≥n.\n",
    "\n",
    "Los resultados muestran c√≥mo se pueden detectar perfiles similares entre postulantes o identificar a quienes tienen caracter√≠sticas excepcionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382aa391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "columnas_cluster = ['PTJE_NEM', 'PTJE_RANKING']\n",
    "datos = datosUnidos_filtrado[columnas_cluster].dropna()\n",
    "scaler = StandardScaler()\n",
    "datos_escalados = scaler.fit_transform(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036255ab",
   "metadata": {},
   "source": [
    "### Algoritmo 1 (KMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff3bcf",
   "metadata": {},
   "source": [
    "#### Configuraci√≥n 1: KMeans sin PCA (3 clusters):\n",
    "Se generaron tres grupos definidos seg√∫n rendimiento. La agrupaci√≥n separa postulantes de alto, medio y bajo rendimiento. Esta segmentaci√≥n es √∫til para categorizar perfiles acad√©micos. No se us√≥ reducci√≥n para mantener fidelidad al rango real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "labels_k3 = kmeans_3.fit_predict(datos_escalados)\n",
    "\n",
    "# Visualizaci√≥n (usamos solo las dos primeras columnas directamente)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(datos_escalados[:, 0], datos_escalados[:, 1], c=labels_k3, cmap='viridis')\n",
    "plt.title(\"KMeans con 3 Clusters (sin PCA)\")\n",
    "plt.xlabel(columnas_cluster[0]); plt.ylabel(columnas_cluster[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80de1d",
   "metadata": {},
   "source": [
    "#### Configuraci√≥n 2 (con PCA): \n",
    "Con PCA aplicado previamente, se logr√≥ visualizar una separaci√≥n m√°s detallada. Aunque algunos clusters est√°n m√°s cerca entre s√≠, la t√©cnica permite explorar agrupaciones intermedias. Es √∫til para analizar diferencias m√°s sutiles entre perfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d596de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_kmeans = PCA(n_components=2)\n",
    "datos_pca_kmeans = pca_kmeans.fit_transform(datos_escalados)\n",
    "\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "labels_k5 = kmeans_5.fit_predict(datos_pca_kmeans)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(datos_pca_kmeans[:, 0], datos_pca_kmeans[:, 1], c=labels_k5, cmap='viridis')\n",
    "plt.title(\"KMeans con 5 Clusters (con PCA)\")\n",
    "plt.xlabel(\"PCA 1\"); plt.ylabel(\"PCA 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1776023",
   "metadata": {},
   "source": [
    "### Algoritmo 2 (DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216e724",
   "metadata": {},
   "source": [
    "##### Se lleva a cabo una reducci√≥n de la cantidad de datos para no saturar la memoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc97790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.utils import resample\n",
    "\n",
    "datos_muestra = resample(datos_escalados, n_samples=int(len(datos_escalados) * 0.10), random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7073e5a",
   "metadata": {},
   "source": [
    "#### Configuraci√≥n 1: DBSCAN sin PCA (eps=0.5):\n",
    "Con una configuraci√≥n estricta, DBSCAN agrup√≥ solo a quienes presentan mucha similitud. Muchos puntos fueron considerados ruido, lo cual permite identificar postulantes con perfiles √∫nicos. Este m√©todo resalta casos at√≠picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_05 = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels_db05 = dbscan_05.fit_predict(datos_muestra)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(datos_muestra[:, 0], datos_muestra[:, 1], c=labels_db05, cmap='plasma')\n",
    "plt.title(\"DBSCAN con eps=0.5 (sin PCA)\")\n",
    "plt.xlabel(columnas_cluster[0]); plt.ylabel(columnas_cluster[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f74e6",
   "metadata": {},
   "source": [
    "#### Conteo de clusters y puntos de ruido para DBSCAN eps=0.5 (sin PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa668c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_05, counts_05 = np.unique(labels_db05, return_counts=True)\n",
    "print(\"DBSCAN eps=0.5 (sin PCA):\")\n",
    "for label, count in zip(unique_labels_05, counts_05):\n",
    "    print(f\"Cluster {label}: {count} puntos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cdcca",
   "metadata": {},
   "source": [
    "#### Configuraci√≥n 2: DBSCAN con PCA (eps=1.0):\n",
    "Con mayor tolerancia y reducci√≥n de dimensiones, se logr√≥ un agrupamiento m√°s amplio. El ruido disminuye, pero los clusters se vuelven menos definidos. Este experimento es √∫til para analizar patrones generales en postulaciones similares.\n",
    "\n",
    "\n",
    "**Observaci√≥n adicional:**  \n",
    "En esta configuraci√≥n, DBSCAN agrup√≥ la mayor√≠a de los puntos en un solo cluster (o como ruido), lo cual indica que `eps=1.0` puede ser demasiado amplio para distinguir agrupaciones relevantes en este conjunto reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dbscan = PCA(n_components=2)\n",
    "datos_pca_muestra = pca_dbscan.fit_transform(datos_muestra)\n",
    "\n",
    "dbscan_10 = DBSCAN(eps=1.0, min_samples=5)\n",
    "labels_db10 = dbscan_10.fit_predict(datos_pca_muestra)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(datos_pca_muestra[:, 0], datos_pca_muestra[:, 1], c=labels_db10, cmap='plasma')\n",
    "plt.title(\"DBSCAN con eps=1.0 (con PCA)\")\n",
    "plt.xlabel(\"PCA 1\"); plt.ylabel(\"PCA 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bc699",
   "metadata": {},
   "source": [
    "#### Conteo de clusters y puntos de ruido para DBSCAN eps=1.0 (con PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_10, counts_10 = np.unique(labels_db10, return_counts=True)\n",
    "print(\"DBSCAN eps=1.0 (con PCA):\")\n",
    "for label, count in zip(unique_labels_10, counts_10):\n",
    "    print(f\"Cluster {label}: {count} puntos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9814b",
   "metadata": {},
   "source": [
    "El uso de PCA en las segundas configuraciones permiti√≥ observar visualmente la estructura de los clusters, destacando su utilidad para interpretabilidad sin modificar los resultados del algoritmo.\n",
    "\n",
    "> Los resultados muestran que KMeans es m√°s √∫til para segmentar perfiles generales, mientras que DBSCAN identifica agrupaciones densas y outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553c787",
   "metadata": {},
   "source": [
    "El objetivo de esta actividad fue **agrupar a los postulantes seg√∫n su rendimiento acad√©mico** usando algoritmos de clustering.  \n",
    "Se eligieron las variables `PTJE_NEM` y `PTJE_RANKING` por ser indicadores cuantificables y comparables del desempe√±o escolar del estudiante, comunes en el proceso de admisi√≥n.\n",
    "\n",
    "Se usaron dos algoritmos (KMeans y DBSCAN), cada uno con dos configuraciones. En la primera configuraci√≥n se usaron los datos escalados directamente. En la segunda, se aplic√≥ PCA para reducir dimensionalidad y facilitar la visualizaci√≥n.\n",
    "\n",
    "Los resultados muestran c√≥mo se pueden detectar perfiles similares entre postulantes o identificar a quienes tienen caracter√≠sticas excepcionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0351b5b",
   "metadata": {},
   "source": [
    "# Actividad 4\n",
    "Se construy√≥ una matriz de postulaciones por estudiante, donde cada fila representaba un postulante y sus carreras postuladas, en formato transaccional.  \n",
    "Se aplic√≥ el algoritmo Apriori con `min_support = 0.009`, obteniendo reglas del tipo:\n",
    "\n",
    "> Ingenier√≠a en Inform√°tica (UTFSM) ‚áí Ingenier√≠a Civil Electr√≥nica (UTFSM)\n",
    "\n",
    "#### Interpretaci√≥n de reglas:\n",
    "- Muchas reglas reflejan **postulaciones a carreras similares dentro de la misma universidad**, como Inform√°tica ‚áî Electr√≥nica o Civil ‚áî Industrial. Esto sugiere que los estudiantes tienen una clara orientaci√≥n de √°rea y usan postulaciones m√∫ltiples como respaldo.\n",
    "- Otras reglas vinculan **carreras similares en distintas universidades** (PUC ‚áí USACH), lo que revela preferencias combinadas por instituci√≥n y especialidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e195b402",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransactionEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     22\u001b[39m postulaciones_por_estudiante = datos_filtrado.groupby(\u001b[33m\"\u001b[39m\u001b[33mID_aux\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mpostulacion\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28mlist\u001b[39m).tolist()\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Ahora transformamos las listas de postulaciones a formato binario usando una matriz dispersa para ahorrar memoria.\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# %% [code]\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Usar matriz dispersa para reducir uso de memoria\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m te = \u001b[43mTransactionEncoder\u001b[49m()\n\u001b[32m     30\u001b[39m te_array = te.fit(postulaciones_por_estudiante).transform(postulaciones_por_estudiante, sparse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     32\u001b[39m df_apriori = pd.DataFrame.sparse.from_spmatrix(te_array, columns=te.columns_)\n",
      "\u001b[31mNameError\u001b[39m: name 'TransactionEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "datosActividad4 =pd.merge(temp,archCodeDelta_Hoja3 , left_on=\"COD_CARRERA_PREF\", right_on=\"CODIGO_CARRERA\", how=\"left\")\n",
    "#datosActividad4[\"postulacion\"] = datosActividad4[[\"NOMBRE_CARRERA\",\"NOMBRE_UNIVERSIDAD\", \"ID_aux\"]]\n",
    "\n",
    "# Asegurarse de que las columnas sean tipo string y sin valores faltantes\n",
    "datosActividad4 = datosActividad4.dropna(subset=[\"NOMBRE_CARRERA\", \"NOMBRE_UNIVERSIDAD\"])\n",
    "datosActividad4[\"NOMBRE_CARRERA\"] = datosActividad4[\"NOMBRE_CARRERA\"].astype(str)\n",
    "datosActividad4[\"NOMBRE_UNIVERSIDAD\"] = datosActividad4[\"NOMBRE_UNIVERSIDAD\"].astype(str)\n",
    "\n",
    "# Crear columna \"postulacion\" combinando carrera y universidad\n",
    "datosActividad4[\"postulacion\"] = datosActividad4[\"NOMBRE_CARRERA\"] + \" (\" + datosActividad4[\"NOMBRE_UNIVERSIDAD\"] + \")\"\n",
    "\n",
    "# Contar frecuencia de cada √≠tem (postulaci√≥n)\n",
    "frecuencias = datosActividad4[\"postulacion\"].value_counts()\n",
    "\n",
    "# Filtrar postulaciones con al menos 100 apariciones\n",
    "postulaciones_frecuentes = frecuencias[frecuencias >= 100].index\n",
    "\n",
    "# Mantener solo esas postulaciones en el dataset\n",
    "datos_filtrado = datosActividad4[datosActividad4[\"postulacion\"].isin(postulaciones_frecuentes)]\n",
    "\n",
    "# Agrupar postulaciones por postulante\n",
    "postulaciones_por_estudiante = datos_filtrado.groupby(\"ID_aux\")[\"postulacion\"].apply(list).tolist()\n",
    "\n",
    "# %% [markdown]\n",
    "# Ahora transformamos las listas de postulaciones a formato binario usando una matriz dispersa para ahorrar memoria.\n",
    "\n",
    "# %% [code]\n",
    "# Usar matriz dispersa para reducir uso de memoria\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(postulaciones_por_estudiante).transform(postulaciones_por_estudiante, sparse=True)\n",
    "\n",
    "df_apriori = pd.DataFrame.sparse.from_spmatrix(te_array, columns=te.columns_)\n",
    "\n",
    "\n",
    "\n",
    "# Convertir a formato binario (uno-hot encoding)\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(postulaciones_por_estudiante).transform(postulaciones_por_estudiante)\n",
    "df_apriori = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Obtener itemsets frecuentes\n",
    "frecuentes = apriori(df_apriori, min_support=0.009, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociaci√≥n (al modificar estas metricas, se modifican las reglas)\n",
    "reglas = association_rules(frecuentes, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "reglas_filtradas = reglas[\n",
    "    (reglas[\"lift\"] >= 1.5) &\n",
    "    (reglas[\"conviction\"] > 1.2) &\n",
    "    (reglas[\"leverage\"] > 0.01)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filtrar reglas v√°lidas\n",
    "reglas_validas = reglas[\n",
    "    (reglas[\"antecedents\"].apply(len) == 1) & \n",
    "    (reglas[\"consequents\"].apply(len) >= 1) # permite mas de un consecuente\n",
    "].copy()\n",
    "# Crear una columna con el formato \"<antecedente> => <consecuente>\"\n",
    "def formatear_regla(row):\n",
    "    antecedente = \", \".join(row[\"antecedents\"])\n",
    "    consecuente = \", \".join(row[\"consequents\"])\n",
    "    cadena = antecedente + \" => \" + consecuente\n",
    "    return cadena\n",
    "\n",
    "reglas_validas[\"regla\"] = reglas_validas.apply(formatear_regla, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Crear columna con antecedente (como string)\n",
    "reglas_filtradas[\"antecedente_texto\"] = reglas_filtradas[\"antecedents\"].apply(lambda x: \", \".join(list(x))) + \" =>\"\n",
    "\n",
    "# Crear columna con consecuente (como string)\n",
    "reglas_filtradas[\"consecuente_texto\"] = reglas_filtradas[\"consequents\"].apply(lambda x: \", \".join(list(x)))\n",
    "\n",
    "# Mostrar las 10 mejores reglas con columnas separadas\n",
    "reglas_filtradas.sort_values(by=\"lift\", ascending=False)[[\"antecedente_texto\", \"consecuente_texto\", \"support\", \"confidence\", \"lift\", \"conviction\"]].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
